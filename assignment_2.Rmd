---
title: "assignment_2"
author: "Timothy Roy"
date: '2023-03-26'
output: html_document
---
```{r, echo=FALSE, include=FALSE}
library(dplyr)
library(arules)
library(skimr)
library(plyr)
library(RColorBrewer)

```
### Task 1 - Product Orders


# Task 1: Product Orders

## a. Data Preparation

### a.1 Familiarize yourself with dataset for product orders



```{r}
store_data <- read.csv("store.csv")
head(store_data)
```

* This data shows information regarding customer's information such as city, country, product purchase, their quantity and sales and other order related information.

### a.2 Document and eliminate any data quality issues that you may find (if you find any), i.e., perform the necessary data cleaning.

```{r}
store_data %>% skim()
```


* The data set has 51,290 rows of data which has 25 columns. 13 of columns are character and 12 is numeric.
* Among numeric columns, only postal code has 41,296 missing values which would not be important for association mining. 
* The data set has a minimum profit of -6,599.978 which is a negative number. However, profit's value can be negative. 
* The minimum sales value is surprisingly low (0.444)!


### a.3 Transforming the data 
In order to run association algorithm among products, `order.id` and `product.name` could be used. `order.id` represents each unique order and `product.name` represents product name that is associated with this order.id. 

First of all, `order.id` and `product.name` will be extracted from `store_data` and then it will be stored in a new data frame named `prod_df`. 

Secondly, product qualification would be removed to find more match of products. If a product's name is "Kraft Clasp Envelope, Set of 50", then the "Set of 50" would be removed to increase the product count. 

Thirdly, using `dplyr` library, product names have been concatenated based on order.id. And afterward, it was saved as a new file named `transactions.csv`. 

```{r}
#data frame with order.id and product.name have been created
sd_ord_prod <- data.frame(store_data$Order.ID, store_data$Product.Name)
colnames(sd_ord_prod) <- c("order.id", "product.name")

#product description has been removed
sd_ord_prod$product.name <- gsub(",.*", "", sd_ord_prod$product.name)

#converted the columns into factors
sd_ord_prod$order.id <- as.factor(sd_ord_prod$order.id)
sd_ord_prod$product.name <- as.factor(sd_ord_prod$product.name)

#using ddply library, based on user ID, the product names concatenated. 
  #head(sd_ord_prod)
transaction_data <- ddply(sd_ord_prod, c("order.id"), function(df1)paste(df1$product.name, collapse= ", "))

#afterwards the file has been saved as csv format
write.csv(transaction_data, "D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/transactions.csv", quote = FALSE, row.names = FALSE)

```


In order to run association algorithm among categories, order.id and sub.category could be used. order.id represents each unique order and sub.category represents category name that is associated with this order.id. 

First of all, order.id and sub.category will be extracted from `store_data` and then it will be stored in a new data frame named `prod_df`. 

Secondly, using `dplyr` library, category names have been concatenated based on order.id. And afterward, it was saved as a new file named `cat_transaction.csv`. 


```{r}

sd_order_cat <- data.frame(store_data$Order.ID, store_data$Sub.Category)
colnames(sd_order_cat) <- c("order.id", "sub.category")

sd_order_cat$order.id <- as.factor(sd_order_cat$order.id)
sd_order_cat$sub.category <- as.factor(sd_order_cat$sub.category)
#head(sd_ord_prod)
cat_transaction_data <- ddply(sd_order_cat, c("order.id"), function(df1)paste(df1$sub.category, collapse= ", "))

write.csv(cat_transaction_data, "D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/cat_transactions.csv", quote = FALSE, row.names = FALSE)
```


## b. Mining Association Rules

In the following the, the `transaction.csv` is being converted to transactions data so that it can be run using the apriori algorithm 

```{r}
tr <- read.transactions("D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/transactions.csv", format ="basket", sep = ",")
#summary(tr)
```


Here it shows the list of top 20 product items by their frequency. 

```{r}
itemFrequencyPlot(tr, topN = 20, type ="absolute", col = brewer.pal(8, 'Pastel2'), main ="Absolute Item Frequency Plot")
```

In the following an association rule algorithm has been ran with 0.0001 support and .1 confidence. 0.0001 support means that customers bought an item set at least 0.01% of the whole transactions. In this case, this is not a significant. However, if support number is increased more than 0.01%, then the association rules do not reutrn any association. 

```{r}
prod_association_rules <- apriori(tr, parameter = list(supp =0.0001, conf = 0.1, maxlen = 10))


```

The apriori algorithm produced 12 item set.They have a very low count and only the top 5 has a relatively high confidence level. Staples are often bought together with items such as chairs, vaccume, xerox, envelop, legal cart, post binders, table. Many of the items that are bought together with staples belong to office supply category. 

Also, printer and Eldon box and Index Tab are bought together. Interstingly toaster and 3 hole punch are bought together. 

As mentioned, these associations are not strong because their support count is low even for some of them the confidence level is higher. 

```{r}
#filter(store_data, Product.Name == "Staples" )
```


```{r}
inspect(prod_association_rules)
```


```{r}
cat_tr <- read.transactions("D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/cat_transactions.csv", format ="basket", sep = ",")
```

```{r}
cat_association_rules <- apriori(cat_tr, parameter = list(supp =0.0006, conf = 0.5))
```
The following table shows category sets and their frequency with confidence level. 0.6% of all the transactions has Binders category in association with  	{Fasteners, Labels, Machines}, {Appliances, Fasteners, Phones}, {Appliances, Fasteners, Paper}, {Appliances, Art, Fasteners} etc. 

```{r}
inspect(cat_association_rules)
```



## c. Mining Multilevel Association Rule

```{r}
library(arules)
df <- read.csv("store.csv")

n_df <- data.frame(df$Order.ID, df$Sub.Category, df$Product.Name)
colnames(n_df) <- c("ord.id", "cat", "prod")

n_df$prod <- gsub(",.*", "", n_df$prod)

n_df_agg <- aggregate(prod ~ ord.id + cat, data = n_df, toString)

n_df_agg <- n_df_agg[,-1]
#multilevel <- addAggregate(n_df_agg, "cat")


#
#itemInfo(trans)

head(n_df_agg)
fin <-  paste(n_df_agg$cat, n_df_agg$prod, sep = ", ")
#head(fin)
#write.csv(fin, "D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/test.csv", quote = FALSE, row.names = FALSE)

trans <- read.transactions("D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/test.csv", format ="basket", sep = ",")

rules <- apriori(trans, parameter = list(supp = 0.001, conf = 0.5))
inspect(rules)

```




# Task 2: Health Data

## a. Data Preparation

### a.1 Familiarize yourself with dataset for product orders

```{r}
health_df <- read.csv("D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/health.csv")


```

```{r}
library(dplyr)
#creating symptoms data frame
sdf <- filter(health_df, type == "S")
head(sdf, 10)
```

```{r}
#conditions data frame
cdf <- filter(health_df, type == "C")
head(cdf,12)
```

```{r}
#treatment dataframe
tdf <- filter(health_df, type == "T")
head(tdf, 12)
```

```{r}
# symptoms aggregation
sdf$reportid <- as.character(sdf$reportid)

```

```{r}
sdf_agg <- aggregate(name ~ reportid, data = sdf, toString)

sdf_agg <- sdf_agg[,-1]
write.csv(sdf_agg, "D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/s.csv", quote = FALSE, row.names = FALSE)

```

```{r}
cdf_agg <- aggregate(name ~ reportid, data = cdf, toString)

cdf_agg <- cdf_agg[,-1]
write.csv(cdf_agg, "D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/c.csv", quote = FALSE, row.names = FALSE)

```

```{r}
tdf_agg <- aggregate(name ~ reportid, data = tdf, toString)
tdf_agg <- tdf_agg[,-1]
write.csv(tdf_agg, "D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/t.csv", quote = FALSE, row.names = FALSE)
```

```{r}
library(arules)
s_trans <- read.transactions("D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/s.csv", format ="basket", sep = ",")

```

```{r}
srules <- apriori(s_trans, parameter = list(supp = .03, conf = .5))
inspect(srules)
```

```{r}

c_trans <- read.transactions("D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/c.csv", format ="basket", sep = ",")

```

```{r}
crules <- apriori(c_trans, parameter = list(supp = .02, conf = .5))
inspect(crules)
```


```{r}

t_trans <- read.transactions("D:/Education/JKU 2023/Summer/Data Mining/market_basket_analysis/t.csv", format ="basket", sep = ",")

```

```{r}
trules <- apriori(t_trans, parameter = list(supp = .02, conf = .5))
inspect(crules)
```


